{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef91105c",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abe042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from skimage.feature import local_binary_pattern\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4cfb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dict ={\n",
    "    \"bellanaija\": [\"https://www.bellanaija.com/2025/11/lagos-fashion-week-2025-see-emmy-kasbits-collection/\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cfb64e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 image elements.\n",
      "All Images from all websites downloaded.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "for web_page, urls in url_dict.items():\n",
    "    folder = os.path.join('kasbit_images', web_page)\n",
    "    if os.path.exists(folder):\n",
    "        continue\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(15)\n",
    "\n",
    "        elements = driver.find_elements(By.TAG_NAME, 'img')\n",
    "        print(f\"Found {len(elements)} image elements.\")\n",
    "\n",
    "        count = 0\n",
    "        for index, img in enumerate(elements):\n",
    "            src = img.get_attribute('src')\n",
    "            if src and src.startswith(\"http\"):\n",
    "                try:\n",
    "                    img_data = requests.get(src).content\n",
    "                    filename = f\"{'kasbit'}_{web_page}_{index+1}.jpg\"\n",
    "                    path = os.path.join(folder, filename)\n",
    "                    with open((path), 'wb') as f:\n",
    "                        f.write(img_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error downloading image {src}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "\n",
    "driver.quit()\n",
    "print(\"All Images from all websites downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5099b8d",
   "metadata": {},
   "source": [
    "PREPROCESSING FOR GENERAL DATASETS - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7aaab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 44 images for kasbit_images.\n",
      "\n",
      "All brands have been preprocessed!\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {\"kasbit_images\": [\"bellanaija\"]}\n",
    "\n",
    "processed_pics = {}\n",
    "\n",
    "for kasbit, folders in dataset_dict.items():\n",
    "    kasbit_img = []\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_dir = os.path.join('kasbit_images', folder)\n",
    "        new_dir = os.path.join(folder_dir, \"processed\")\n",
    "        os.makedirs(new_dir, exist_ok = True)\n",
    "        \n",
    "        for img_name in os.listdir(folder_dir):\n",
    "            img_path = os.path.join(folder_dir, img_name)\n",
    "           \n",
    "            if not img_name.lower().endswith(('.jpg','.jpeg', '.png')):\n",
    "                continue\n",
    "            \n",
    "            if \"processed\" in img_path:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (224,224))\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img_norm = img / 255.0\n",
    "                    kasbit_img.append(img_norm)\n",
    "                    cv2.imwrite(os.path.join(new_dir, img_name), cv2.cvtColor((img_norm * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_name}: {e}\")\n",
    "                continue\n",
    "    processed_pics[kasbit] = np.array(kasbit_img)\n",
    "    print(f\"Processed {len(kasbit_img)} images for {kasbit}.\\n\")\n",
    "\n",
    "print(\"All brands have been preprocessed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a2f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Lagos-FW-2024-Analysis\\Lagos-FW-2024-Analysis-1\\fw_env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 9s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mini_CNN = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "imgen = ImageDataGenerator(rescale=1./255)\n",
    "gen = imgen.flow_from_directory('kasbit_images', target_size=(224,224), batch_size=32, class_mode=None, shuffle=False)\n",
    "\n",
    "features = mini_CNN.predict(gen)\n",
    "\n",
    "filenames = gen.filenames\n",
    "np.save('kasbit_features.npy', features)\n",
    "np.save('kasbit_files.npy', filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed638cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_colors(image_path, n_colors=5):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    \n",
    "    # Reshape pixels for clustering\n",
    "    pixels = img.reshape(-1, 3)\n",
    "    \n",
    "    # Use KMeans to find dominant colors\n",
    "    from sklearn.cluster import KMeans\n",
    "    from skimage.feature import local_binary_pattern\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_colors)\n",
    "    kmeans.fit(pixels)\n",
    "    \n",
    "    colors = kmeans.cluster_centers_.astype(int)\n",
    "    counts = np.bincount(kmeans.labels_)\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_colors = colors[np.argsort(-counts)]\n",
    "    return sorted_colors\n",
    "\n",
    "def extract_sihlouette(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = img/255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    X = mini_CNN.predict(img, verbose=0)\n",
    "    return X.flatten()\n",
    "\n",
    "def extract_texture(image_path, P=8, R=1):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    \n",
    "    lbp = local_binary_pattern(img, P, R, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, P + 3), range=(0, P + 2))\n",
    "    \n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c59f56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrembg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      3\u001b[0m silhouettes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Lagos-FW-2024-Analysis\\Lagos-FW-2024-Analysis-1\\fw_env\\lib\\site-packages\\rembg\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _version\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m _version\u001b[38;5;241m.\u001b[39mget_versions()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m new_session\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Lagos-FW-2024-Analysis\\Lagos-FW-2024-Analysis-1\\fw_env\\lib\\site-packages\\rembg\\bg.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Tuple, Union, cast\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mort\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     BORDER_DEFAULT,\n\u001b[0;32m     10\u001b[0m     MORPH_ELLIPSE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     morphologyEx,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "from rembg import remove\n",
    "import io\n",
    "silhouettes = []\n",
    "\n",
    "folder = 'kasbit_images/lagos fashion week/processed'\n",
    "for img_name in os.listdir(folder):\n",
    "    img_path = os.path.join(folder, img_name)\n",
    "    if img_name.lower().endswith(('.jpg','.jpeg', '.png')):\n",
    "        with open(img_path, 'rb') as inp:\n",
    "            output = remove(inp.read())\n",
    "        silhouette_img = Image.open(io.BytesIO(output))\n",
    "        silhouette_img.save(os.path.join(folder, f\"silhouette_{img_name}\"))\n",
    "        img = cv2.imread(os.path.join(folder, f\"silhouette_{img_name}\"))\n",
    "        grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(grayscale, 10, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        mask = np.zeros_like(grayscale)\n",
    "        cv2.drawContours(mask, contours, -1, 255, -1)\n",
    "        silhouette = np.zeros_like(img)\n",
    "        silhouette[mask == 255] = (0,0,0)\n",
    "        plt.imshow(silhouette)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5251d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_colors = []\n",
    "silhouettes = []\n",
    "textures = []\n",
    "\n",
    "folder = 'kasbit_images/lagos fashion week/processed'\n",
    "for img_name in os.listdir(folder):\n",
    "    if img_name.endswith(('.jpg','.png')):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        colors = extract_colors(img_path, n_colors=3)\n",
    "        brand_colors.extend(colors)\n",
    "\n",
    "        silhouettes.append(extract_sihlouette(img_path))\n",
    "        textures.append(extract_texture(img_path))\n",
    "\n",
    "# Convert to NumPy array\n",
    "brand_colors = np.array(brand_colors)\n",
    "silhouettes_features = np.array(silhouettes)\n",
    "textures = np.array(textures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "679bd647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common colors for brand: [[ 60  62  67]\n",
      " [185 192 210]\n",
      " [206  52  69]\n",
      " [150 141  78]\n",
      " [147 145 148]]\n"
     ]
    }
   ],
   "source": [
    "# Optional: cluster all colors across images to find overall dominant colors\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_all = KMeans(n_clusters=5)\n",
    "kmeans_all.fit(brand_colors)\n",
    "common_colors = kmeans_all.cluster_centers_.astype(int)\n",
    "\n",
    "print(\"Most common colors for brand:\", common_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbda4c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAABhCAYAAADx7Ve+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAcZJREFUeJzt17FNA0EQQNE7RFGEEFEDseWc1CIhtOSYWiiFyLm7WErA0n3pON178Wh3sq+ZxxhjAoCFHpY+AACCAkDGhQJAQlAASAgKAAlBASAhKAAkBAWAhKAAkHi8d/D55bX5cUc+Pi9rr7A515/z2itsztPXbe0VNuf7cFx7hc05vb/9OeNCASAhKAAkBAWAhKAAkBAUABKCAkBCUABICAoACUEBICEoACQEBYCEoACQEBQAEoICQEJQAEgICgAJQQEgISgAJAQFgISgAJAQFAASggJAQlAASAgKAAlBASAhKAAkBAWAhKAAkBAUABKCAkBCUABICAoACUEBICEoACQEBYCEoACQEBQAEoICQEJQAEgICgAJQQEgISgAJAQFgISgAJAQFAASggJAQlAASAgKAAlBASAhKAAkBAWAhKAAkBAUABKCAkBCUABICAoACUEBICEoACQEBYCEoACQEBQAEoICQEJQAEgICgAJQQEgISgAJAQFgISgAJAQFAASggKAoADwf7hQAEgICgAJQQEgISgAJAQFgMQ8xhjNUwDsmQsFgISgAJAQFAASggJAQlAASAgKAAlBASAhKAAkBAWAqfALThkRuxfTxLEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,1))\n",
    "plt.imshow([common_colors])\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color [192 199 216] appears in 22.84% of the collection\n",
      "Color [55 55 59] appears in 42.29% of the collection\n",
      "Color [178  88  71] appears in 4.72% of the collection\n",
      "Color [70 76 85] appears in 22.16% of the collection\n",
      "Color [152 166 179] appears in 8.00% of the collection\n"
     ]
    }
   ],
   "source": [
    "folder = 'kasbit_images/lagos fashion week/processed'\n",
    "all_colors = []\n",
    "\n",
    "for img_name in os.listdir(folder):\n",
    "    if img_name.lower().endswith(('.jpg', '.png')):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        pixels = img.reshape(-1, 3)\n",
    "        color_fraction_list = extract_colors(img_path, n_colors=3)\n",
    "        all_colors.append(pixels)\n",
    "\n",
    "all_colors = np.vstack(all_colors)\n",
    "\n",
    "\n",
    "overall_k = 5  # number of main colors for the collection\n",
    "kmeans_all = KMeans(n_clusters=overall_k, random_state=42)\n",
    "labels = kmeans_all.fit_predict(all_colors)  # weight by pixel fraction\n",
    "\n",
    "dominant_colors = kmeans_all.cluster_centers_.astype(int)\n",
    "\n",
    "# Calculate fraction of each dominant color\n",
    "color_percentages = []\n",
    "\n",
    "for i in range(overall_k):\n",
    "    color_fraction = np.sum(labels == i) / len(labels)\n",
    "    color_percentages.append(color_fraction * 100)\n",
    "\n",
    "for color, perc in zip(dominant_colors, color_percentages):\n",
    "    print(f\"Color {color} appears in {perc:.2f}% of the collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7145013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common silhouttes for brand: [2 2 1 1 1 3 3 1 1 4 0 0 2 2 2 3 2 2 1 1 1 3 3 1 1 4 0 0 2 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Optional: cluster all colors across images to find overall dominant colors\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_shape = KMeans(n_clusters=5, random_state=42)\n",
    "#kmeans_shape.fit(silhouettes)\n",
    "common_shapes = kmeans_shape.fit_predict(pca_results)\n",
    "\n",
    "print(\"Most common silhouttes for brand:\", common_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16787da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAAiCAYAAACOaKrkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAARFJREFUeJzt3TFqAkEYhuFZ8RTbCVZJYyXa2Hokz5AiBAsLGyFX0cITaOVdJngCRcjut/I89Qx/9fMyzW5Ta60FAOjVqN/xAMCdIANAAEEGgACCDAABBBkAAggyAAQQZAAIIMgAEGD87MHJ9rt0rT0O65sl082185m3r4/OZ552+5furdtZ6drtZ1GGZLW8vHTveP4sfRjSjtrPx+zo/+zn3e/88PCMFzIABBBkAAggyAAQQJABIIAgA0AAQQaAAIIMAAEEGQACCDIABBBkAAggyAAQQJABIIAgA0AAQQaAAE2tdTj/TwOAN+WFDAABBBkAAggyAAQQZAAIIMgAEECQASCAIANAAEEGgACCDAClf3+yViE9MMXw+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,1))\n",
    "plt.imshow([common_shapes])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085939c",
   "metadata": {},
   "source": [
    "DEEPLABV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c443e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.transforms.functional import resize\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b28466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_mobilenet_v3_large-fc3c493d.pth\" to C:\\Users\\User/.cache\\torch\\hub\\checkpoints\\deeplabv3_mobilenet_v3_large-fc3c493d.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42.3M/42.3M [00:04<00:00, 10.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented 44 images for kasbit_images.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((520,520)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "dataset_dict = {\"kasbit_images\": [\"bellanaija\"]}\n",
    "preprocessed_images = {}\n",
    "\n",
    "for kasbit, folders in dataset_dict.items():\n",
    "    kasbit_img = []\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_dir = os.path.join(kasbit, folder)\n",
    "        \n",
    "        for img_name in os.listdir(folder_dir):\n",
    "            img_path = os.path.join(folder_dir, img_name)\n",
    "           \n",
    "            if not img_name.lower().endswith(('.jpg','.jpeg', '.png')):\n",
    "                continue\n",
    "            \n",
    "            if \"segmented\" in img_path:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                input_image = Image.open(img_path).convert(\"RGB\")\n",
    "                input_tensor = preprocess(input_image)\n",
    "                kasbit_img.append(input_tensor)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "    preprocessed_images[kasbit] = torch.stack(kasbit_img)\n",
    "    print(f\"Segmented {len(kasbit_img)} images for {kasbit}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361808ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOURS = {\"Black\": [0, 0, 0], \"White\": [100, 0, 0], \"Gray\": [50, 0, 0],\n",
    "    \"Red\": [53, 80, 67], \"Blue\": [32, 79, -107], \"Green\": [87, -86, 83],\n",
    "    \"Navy\": [12, 10, -35], \"Beige\": [85, 5, 20], \"Burgundy\": [25, 45, 15],\n",
    "    \"Olive\": [45, -10, 30], \"Pink\": [85, 15, 5], \"Yellow\": [97, -21, 94]}\n",
    "\n",
    "def get_colour_name(lab_pixel):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation completed for kasbit_images.\n",
      "\n",
      "Masks extracted for kasbit_images.\n",
      "\n",
      "Garment images extracted and converted to LAB for all brands.\n"
     ]
    }
   ],
   "source": [
    "model2 = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(weights='DEFAULT')\n",
    "\n",
    "model2.eval()\n",
    "\n",
    "seg_outputs = {}\n",
    "seg_masks = {}\n",
    "garment_masks = {}\n",
    "garment_img = {}\n",
    "garment_lab = {}\n",
    "garment_pixels_flat = {}\n",
    "garment_colours = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for kasbit, images in preprocessed_images.items():\n",
    "        outputs = model2(images)['out']\n",
    "        seg_outputs[kasbit] = outputs\n",
    "        print(f\"Segmentation completed for {kasbit}.\\n\")\n",
    "\n",
    "for kasbit, outputs in seg_outputs.items():\n",
    "    masks = torch.argmax(outputs, dim=1)\n",
    "    seg_masks[kasbit] = masks\n",
    "    print(f\"Masks extracted for {kasbit}.\\n\")\n",
    "\n",
    "for kasbit, masks in seg_masks.items():\n",
    "    garment_masks[kasbit] = masks != 0\n",
    "\n",
    "for kasbit, masks in garment_masks.items():\n",
    "    masked_img = []\n",
    "    lab_img = []\n",
    "    flattened_pixels = []\n",
    "    colour_list = []\n",
    "\n",
    "    for i, mask in enumerate(masks):\n",
    "        img_path = os.path.join(kasbit, dataset_dict[kasbit][0], os.listdir(os.path.join(kasbit, dataset_dict[kasbit][0]))[i])\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = resize(img, mask.shape[-2:])\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        mask_np = mask.cpu().numpy()\n",
    "        masked = img_np * mask_np[:, :, None]\n",
    "        masked_img.append(masked)\n",
    "\n",
    "        img_lab = cv2.cvtColor(masked.astype(np.uint8), cv2.COLOR_RGB2LAB)\n",
    "        lab_img.append(img_lab)\n",
    "        \n",
    "        pixels_flat = img_lab[mask_np]\n",
    "        flattened_pixels.append(pixels_flat)\n",
    "\n",
    "        if len(pixels_flat) > 0:\n",
    "            n = 5\n",
    "            kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "            kmeans.fit(pixels_flat)\n",
    "            colour_list.append(kmeans.cluster_centers_)\n",
    "        else:\n",
    "            colour_list.append(np.zeros((n, 3)))\n",
    "\n",
    "    garment_img[kasbit] = masked_img\n",
    "    garment_lab[kasbit] = lab_img\n",
    "    garment_pixels_flat[kasbit] = flattened_pixels\n",
    "    garment_colours[kasbit] = colour_list\n",
    "\n",
    "print(\"Garment images extracted and converted to LAB for all brands.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
